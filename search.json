[
  {
    "objectID": "posts/map-and-filter.html",
    "href": "posts/map-and-filter.html",
    "title": "Map and Filter",
    "section": "",
    "text": "Although PEP 8 is silent on the topic, it’s become recommended in many Python circles to eschew map and filter in favor of generator expressions or list comprehensions. For example, this Stack Overflow question received and accepted a typical response. Ironically, that question misquoted the google style guide, which this author happens to agree with.\n\nUse list comprehensions and for loops instead of filter and map when the function argument would have been an inlined lambda anyway. [emphasis added]\n\nThe style guide also shows a non-lambda version as a positive example: > map(math.sqrt, data) # Ok. No inlined lambda expression.\nFirst, a brief history of how the Python community arrived at this state.\n\n\nPrior to version 2.0, Python had neither list comprehensions nor nested scopes. Therefore simple map and filter operations had to use a for... append loop, or lambda. But the lacked of nested scopes was inherently crippling to the latter approach.\n\nx = 2\nmap(lambda y: y * x, range(5))\n\n<map at 0x108e57250>\n\n\nA NameError would have been raised on x, because it’s not defined in the inner scope. One clever work-around was to shadow default arguments.\n\nx = 2\nlist(map(lambda y, x=x: y * x, range(5)))\n\n[0, 2, 4, 6, 8]\n\n\nUnsurprisingly, that was widely viewed as an ugly hack. Many resigned themselves to for... append loops instead.\n\n\n\nThen Python added list comprehensions in 2.0, and that became the one obvious way to do it.\n\nx = 2\n[y * x for y in range(5)]\n\n[0, 2, 4, 6, 8]\n\n\nPython acquired nested scopes in the next version, 2.1, but the damage was done. Functional programming in Python in general, and lambda in particular, was widely frowned upon. Even though the lack of nested scopes affected all inner functions used in any context; it was never really about lambda per se.\n\n\n\nIt’s sometimes claimed to this day that map and filter only exist for backwards compatibility. But that belies the history of Python 3. map, filter, and reduce were all considered for removal. But only reduce was banished to the functools module. map and filter were not only retained, but updated to return iterators.\nSo it’s already dubious to claim that using a built-in is unapproved. But the real point is that map and filter remain a higher level abstraction. Sure, with lambda there are the same number of logical components, and it’s just a matter of syntactic sugar. But there is some abstraction value when the functions already have a name.\nIt’s also commonly pointed out that generator expressions are superior because they can do a map and filter simultaneously, but crucially only if the filter comes first. Consider this task: normalizing an iterable of strings.\n\nvalues = 'sample ', ' '\nlist(filter(None, map(str.strip, values)))\n\n['sample']\n\n\nNote list is only being used for printing, and should be ignored for the sake of comparisons.\nAs for the alternative, surely calling strip twice to use a single expression is just plain cheating. So really the only option is:\n\n[value for value in (value.strip() for value in values) if value]\n\n['sample']\n\n\nSome would consider nested comprehensions already enough to separate with a temporary name. But that’s inadvertently acknowledging how much more verbose it is.\nCan it really be claimed that the latter is more readable than the former? It’s just boilerplate, which never seems acknowledged in small examples. But if one only has to double the size of the context to show how verbose comprehensions are, doesn’t that demonstrate the value of map and filter.\n\n\n\nAnd now a shameless plug of the author’s placeholder package for readers who appreciate function-style programming. It provides syntactic sugar for lambda.\n\nfrom placeholder import _\n\nlist(map(_ * 2, range(5)))\n\n[0, 2, 4, 6, 8]\n\n\nBut even speaking as the author, map isn’t the best use case. Sort keys are a much better example, since there is no competing syntax.\n\nmin(['ab', 'ba'], key=_[-1])\n\n'ba'\n\n\nPython 3.8’s new assignment expressions provide yet another alternative."
  },
  {
    "objectID": "posts/cheryls-birthday.html",
    "href": "posts/cheryls-birthday.html",
    "title": "Cheryl’s Birthday",
    "section": "",
    "text": "Albert and Bernard just became friends with Cheryl, and they want to know when her birthday is. Cheryl gave them a list of 10 possible dates:\n\n\n    May 15     May 16     May 19\n   June 17    June 18\n   July 14    July 16\n August 14  August 15  August 17\n\nCheryl then tells Albert and Bernard separately the month and the day of the birthday respectively.\nAlbert: I don’t know when Cheryl’s birthday is, but I know that Bernard does not know too.\nBernard: At first I don’t know when Cheryl’s birthday is, but I know now.\nAlbert: Then I also know when Cheryl’s birthday is.\nSo when is Cheryl’s birthday?\n\nAs with the pytudes solution, the goal is to solve the puzzle in code. A different approach is taken here though, for simplicity and extensibility.\nThe first step is to model the data. A set of Date objects is suitable to represent the current possible dates. Since datetime.date objects require a year, a minimal collections.namedtuple is used instead.\n\nfrom typing import NamedTuple\n\nDATES = ['May 15',    'May 16',    'May 19',\n        'June 17',   'June 18',\n        'July 14',   'July 16',\n      'August 14', 'August 15', 'August 17']\n\nclass Date(NamedTuple):\n    month: str\n    day: str\n\n    def __repr__(self):\n        return ' '.join(self)  # pretty printing\nDATES = {Date(*date.split()) for date in DATES}\nDATES\n\n{August 14,\n August 15,\n August 17,\n July 14,\n July 16,\n June 17,\n June 18,\n May 15,\n May 16,\n May 19}\n\n\nAs is typical of these kinds of puzzles, it assumes all participants have perfect Theory of Mind. That is, each participant making a statement is applying their private knowledge to what is publicly known, and assuming everyone else will do the same. With that in mind, the claims made fall into 3 categories: * I know … * I don’t know … * They don’t know …\nThe temporal variations “now” and “at first” can be modeled by the current set of dates. Any claim then can be implemented functionally in this form:\n\ndef claim(field: str, dates: set) -> set:\n    \"\"\"Return subset of possible dates which would make the claim true.\n    \n    :param field: the field known by the claimant\n    :param dates: the current set of dates publicly known\n    \"\"\"\n\nSo what does it mean for Albert or Bernard to “know” the correct date? It would mean applying their knowledge of the month or day leaves only one possibility. The “I know …” function therefore groups and filters for uniqueness.\n\nimport collections\n\ndef known(field, dates):\n    \"\"\"Return subset of possible dates which would make the claim \"I know ...\" true.\"\"\"\n    counts = collections.Counter(getattr(date, field) for date in dates)\n    return {date for date in dates if counts[getattr(date, field)] == 1}\n\n# test what is already publicly known\nassert known('month', DATES) == set()\nknown('day', DATES)\n\n{June 18, May 19}\n\n\nTo implement “I don’t know …”, known could be parametrized with a different predicate (> 1), or simply use set.difference. “I don’t know …” is so trivial it’s arguably not worth the abstraction.\n\ndef unknown(field, dates):\n    \"\"\"Return subset of possible dates which would make the claim \"I don't know ...\" true.\"\"\"\n    return dates - known(field, dates)\n\nThe challenging part is what does it mean for Albert to claim Bernard doesn’t know. All dates that would be knowable to Bernard must clearly be excluded, but Albert would have to exclude them based on his knowledge of the month. So “They don’t know …” is similar to unknown, but the exclusion is based on a different field.\n\ndef unknowable(field, dates):\n    \"\"\"Return subset of possible dates which would make the claim \"They don't know ...\" true.\"\"\"\n    other, = set(Date._fields) - {field}\n    exclude = {getattr(date, field) for date in known(other, dates)}\n    return {date for date in dates if getattr(date, field) not in exclude}\n\nThis is sufficient to simply walk through the statements, one at a time.\n\n# Albert: I don't know when Cheryl's birthday is, but I know that Bernard does not know too.\ndates = unknown('month', DATES)\nassert dates == DATES  # already public known\ndates = unknowable('month', dates)\ndates\n\n{August 14, August 15, August 17, July 14, July 16}\n\n\n\n# Bernard: At first I don't know when Cheryl's birthday is, but I know now.\nassert dates.isdisjoint(known('day', DATES))  # already claimed by Albert\ndates = known('day', dates)\ndates\n\n{August 15, August 17, July 16}\n\n\n\n# Albert: Then I also know when Cheryl's birthday is.\nknown('month', dates)\n\n{July 16}\n\n\nExactly one date is left, indicating success. Now the succinct in-lined version, with no superfluous statements.\n\nknown('month',                        # Albert: I know\n    known('day',                      # Bernard: I know\n        unknowable('month', DATES)))  # Albert: Bernard doesn't know\n\n{July 16}"
  },
  {
    "objectID": "posts/closing-files.html",
    "href": "posts/closing-files.html",
    "title": "Closing files",
    "section": "",
    "text": "It has become conventional wisdom to always explicitly close file-like objects, via context managers. The google style guide is representative:\n\nExplicitly close files and sockets when done with them. Leaving files, sockets or other file-like objects open unnecessarily has many downsides, including:\n\n\nThey may consume limited system resources, such as file descriptors. * Code that deals with many such objects may exhaust those resources unnecessarily if they’re not returned to the system promptly after use. * Holding files open may prevent other actions being performed on them, such as moves or deletion. * Files and sockets that are shared throughout a program may inadvertantly be read from or written to after logically being closed. If they are actually closed, attempts to read or write from them will throw exceptions, making the problem known sooner.\n\n\nFurthermore, while files and sockets are automatically closed when the file object is destructed, tying the life-time of the file object to the state of the file is poor practice, for several reasons: * There are no guarantees as to when the runtime will actually run the file’s destructor. Different Python implementations use different memory management techniques, such as delayed Garbage Collection, which may increase the object’s lifetime arbitrarily and indefinitely. * Unexpected references to the file may keep it around longer than intended (e.g. in tracebacks of exceptions, inside globals, etc).\n\n\nThe preferred way to manage files is using the “with” statement:\n\nwith open(\"hello.txt\") as hello_file:\n    for line in hello_file:\n        print line\n\n\nGood points, and why limit this advice to file descriptors? Any resource may be limited or require exclusivity; that’s why they’re called resources. Similarly one should always explicitly call dict.clear when finished with a dict. After all, “there are no guarantees as to when the runtime will actually run the <object’s> destructor. And”code that deals with many such objects may exhaust those resources unnecessarily”, such as memory, or whatever else is in the dict.\nBut in all seriousness, this advice is applying a notably higher standard of premature optimization to file descriptors than to any other kind of resource. There are plenty of Python projects that are guaranteed to run on CPython for a variety of reasons, where destructors are immediately called. And there are plenty of Python projects where file descriptor usage is just a non-issue. It’s now depressingly commonplace to see this in setup.py files:\n\nwith open(\"README.md\") as readme:\n    long_description = readme.read()\n\nLet’s consider a practical example: a load function which is supposed to read and parse data given a file path.\n\nimport csv\nimport json\n\ndef load(filepath):\n    \"\"\"the supposedly bad way\"\"\"\n    return json.load(open(filepath))\n\ndef load(filepath):\n    \"\"\"the supposedly good way\"\"\"\n    with open(filepath) as file:\n        return json.load(file)\n\ndef load(filepath):\n    \"\"\"with a different file format\"\"\"\n    with open(filepath) as file:\n        return csv.reader(file)\n\nWhich versions work correctly? Are you sure? If it’s not immediately obvious why one of these is broken, that’s the point. In fact, it’s worth trying out before reading on.\n…\nThe csv version returns an iterator over a closed file. It’s a violation of procedural abstraction to know whether the result of load is lazily evaluated or not; it’s just supposed to implement an interface. Moreover, according to this best practice, it’s impossible to write the csv version correctly. As absurd as it sounds, it’s just an abstraction that can’t exist.\nDefiantly clever readers are probably already trying to fix it. Maybe like this:\n\ndef load(filepath):\n    with open(filepath) as file:\n        yield from csv.reader(file)\n\nNo, it will not be fixed. This version only appears to work by not closing the file until the generator is exhausted or collected.\nThis trivial example has deeper implications. If one accepts this practice, then one must also accept that storing a file handle anywhere, such as on an instance, is also disallowed. Unless of course that object then virally implements it owns context manager, ad infinitum.\nFurthermore it demonstrates that often the context is not being managed locally. If a file object is passed another function, then it’s being used outside of the context. Let’s revisit the json version, which works because the file is fully read. Doesn’t a json parser have some expensive parsing to do after it’s read the file? It might even throw an error. And isn’t it desirable, trivial, and likely that the implementation releases interest in the file as soon as possible?\nSo in reality there are scenarios where the supposedly good way could keep the file open longer than the supposedly bad way. The original inline version does exactly what it’s supposed to do: close the file when all interested parties are done with it. Python uses garbage collection to manage shared resources. Any attempt to pretend otherwise will result in code that is broken, inefficient, or reinventing reference counting.\nA true believer now has to accept that json.load is a useless and dangerous wrapper, and that the only correct implementation is:\n\ndef load(filepath):\n    with open(filepath) as file:\n        contents = file.read()\n    return json.loads(contents)\n\nThis line of reasoning reduces to the absurd: a file should never be passed or stored anywhere. Next an example where the practice has caused real-world damage.\n\n\n\nRequests is one of the most popular python packages, and officially recommended. It includes a Session object which supports closing via a context manager. The vast majority of real-world code uses the the top-level functions or single-use sessions.\n\nresponse = requests.get(...)\n\nwith requests.Session() as session:\n    response = session.get(...)\n\nSessions manage the connection pool, so this pattern of usage is establishing a new connection every time. There are popular standard API clients which seriously do this, for every single request to the same endpoint.\nRequests’ documentation prominently states that “Keep-alive and HTTP connection pooling are 100% automatic”. So part of the blame may lay with that phrasing, since it’s only “automatic” if sessions are reused. But surely a large part of the blame is the dogma of closing sockets, and therefore sessions, explicitly. The whole point of a connection pool is that it may leave connections open, so users who genuinely need this granularity are working at the wrong abstraction layer. http.client is already builtin for that level of control.\nTellingly, requests’ own top-level functions didn’t always close sessions. There’s a long history to that code, including a version that only closed sessions on success. An older version was causing warnings, when run to check for such warnings, and was being blamed for the appearance of leaking memory. Those threads are essentially debating whether a resource pool is “leaking” resources.\n\n\n\nPrior to with being introduced in Python 2.5, it was not recommended that inlined reading of a file required a try... finally block. Far from it, in the past idioms like open(...).read() and for line in open(...) were lauded for being succinct and expressive. But if all this orphaned file descriptor paranoia was well-founded, it would have been a problem back then too.\nFinally, let’s address readability. It could be argued (though it rarely is) that showing the reader when the file is closed has inherent value. Conveniently, that tends to align with having opened the file for writing anyway, thereby needing an reference to it. In which case, the readability is approximately equal, and potential pitfalls are more realistic. But readability is genuinely lost when the file would have been opened in a inline expression.\nThe best practice is unjustifiably special-casing file descriptors, and not seeing its own reasoning through to its logical conclusion. This author proposes advocating for anonymous read-only open expressions. Your setup script is not going to run out of file descriptors because you wrote open(\"README.md\").read()."
  },
  {
    "objectID": "posts/mutable-defaults.html",
    "href": "posts/mutable-defaults.html",
    "title": "Mutable defaults",
    "section": "",
    "text": "Contrarian view on mutable default arguments.\nThe use of mutable defaults is probably the most infamous Python gotcha. Default values are evaluated at definition time, which means mutating them will be persistent across multiple calls. Many articles on this topic even use the same append example.\n\ndef append_to(element, to=[]):\n    to.append(element)\n    return to\n\nappend_to(0)\n\n[0]\n\n\n\nappend_to(1)\n\n[0, 1]\n\n\nAnd the solution is invariably to use None instead, and convert as needed.\n\ndef append_to(element, to=None):\n    if to is None:\n        to = []\n    to.append(element)\n    return to\n\nThere is another solution to the problem of mutating a default value: don’t do that. More specifically, the problem isn’t using mutables as defaults; the problem is actually mutating them.\nIf the input from the caller is being mutated, then the caller doesn’t need it returned because the caller already has a reference. This distinction is explicitly encouraged in Python, e.g., list.sort vs. sorted. But it follows that if the input doesn’t need to be returned, then there’s no point in the input being optional. How would the caller know the difference?\nThe reason why examples like the fluent append seem so contrived is because they are. No one actually wants a function named append to take one argument. The realistic fix would be:\n\ndef append_to(element, to):\n    to.append(element)\n    return to\n\nSure, there are rare occassions where a parameter is mutable but optional, such as a recursive algorithm that’s implicitly passing around its own cache. But this author would wager that given any real-world code that’s been bitten by this gotcha there is: * a ~90% chance the function would have a related bug if defaults were evaluated at runtime * a ~95% chance the function has a poor interface\nWhat harm does this advice do? Well, it’s caused an over-reaction resulting in using None as the only default, even for immutables. It’s so prevalent that it appears many beginners believe using None is the one and only way of making an argument optional.\nBesides immutable types, there are also cases where mutation is irrelevant. Consider the following example adapted from a popular project.\n\nfrom typing import List\n\ndef __init__(self, alist: List = None):\n    self.alist = [] if alist is None else list(alist)\n\nNotice that the correctness of this code relies on the member list being newly created in either case. What could possibly go wrong with:\n\ndef __init__(self, alist: List = []):\n    self.alist = list(alist)\n\nOr better yet, why not support the more liberal interface.\n\nfrom typing import Iterable\n\ndef __init__(self, alist: Iterable = ()):\n    self.alist = list(alist)\n\nThe point is that there are at least 4 solutions to this problem:\n\nuse mutable defaults, but don’t mutate them\nuse immutable substitute defaults with a compatible interface\nuse None for mutables, and matching types for immutables\nuse None for all defaults\n\nOnly #1 is even remotely controversial, yet somehow the status quo has landed on #4. Besides being needlessly verbose, it has another pitfall. Python doesn’t natively support detecting where the argument was actually passed; a sentinel default is required for that. The implementation detail is leaking through the interface, indicating to the caller that None is an acceptable argument to pass explicitly. As if the type hint was Optional[List], even though that’s not the intention. Factor in using **kwargs - which clearly doesn’t want data padded with nulls - and actual code breakage can result.\nPresumably the disdain for option #1 is because it might encourage the gotcha. But it’s disingenous to just let that go unsaid. The implementer is responsible for writing correct code, and the caller sees the right interface. The speculation is that beginners will read code which uses mutable defaults but doesn’t mutate them, and follow the former pattern but not the latter.\nAs a community, let’s at least push towards option #3. Using empty strings and zeros as defaults is all upside."
  },
  {
    "objectID": "posts/split-an-iterable.html",
    "href": "posts/split-an-iterable.html",
    "title": "Split an Iterable",
    "section": "",
    "text": "A common task and interview question, with many variants. It’s frequently asked and answered in a way that’s suboptimal and only handles one specific case. The goal here is to present definitive, general, and efficient solutions.\nThe first variant is whether or not the chunks will overlap. Although this could be generalized into a step parameter, it’s nearly always the case that step in (1, size).\nThe second variant is whether the tail of the data should be returned, if it’s not of equal size. Clearly when step == 1 that’s unlikely to be desirable. However, when step == size, that would seem to be the natural choice. And again when 1 < step < size, the desired behavior isn’t clear at all.\nThe third variant is whether to slice sequences, or support any iterable. Obviously working for any iterable would be ideal, but it’s also likely a user would expect slices given a sequence, particularly in the case of strings.\nSo this author feels it’s best to split the problem in 2 distinct cases: a sliding window for overlapping sequences, and chunks for discrete sequences. In each case, supporting iterables and using advanced iterator algebra for a minimal and efficient solution.\n\n\n\nimport itertools\n\ndef window(iterable, size=2):\n    \"\"\"Generate a sliding window of values.\"\"\"\n    its = itertools.tee(iterable, size)\n    return zip(*(itertools.islice(it, index, None) for index, it in enumerate(its)))\n\nlist(window('abcde'))\n\n[('a', 'b'), ('b', 'c'), ('c', 'd'), ('d', 'e')]\n\n\nThat’s simple, and close to optimal. There is slight overhead in iterating an islice object, so a minor variant would be to force the step-wise iteration in advance.\n\nimport collections\n\ndef window(iterable, size=2):\n    \"\"\"Generate a sliding window of values.\"\"\"\n    its = itertools.tee(iterable, size)\n    for index, it in enumerate(its):\n        collections.deque(itertools.islice(it, index), 0)  # exhaust iterator\n    return zip(*its)\n\nlist(window('abcde'))\n\n[('a', 'b'), ('b', 'c'), ('c', 'd'), ('d', 'e')]\n\n\n\n\n\nA lesser-known and under-utilized feature of iter is that in can take a callable (of no arguments) and a sentinel to create an iterator. A perfect use case of the “loop and a half” idiom.\n\ndef chunks(iterable, size):\n    \"\"\"Generate adjacent chunks of data\"\"\"\n    it = iter(iterable)\n    return iter(lambda: tuple(itertools.islice(it, size)), ())\n\nlist(chunks('abcde', 3))\n\n[('a', 'b', 'c'), ('d', 'e')]\n\n\nThis should also be optimal, for reasonable sizes.\n\n\n\nRather than explicitly check isinstance, this is a perfect use case for functools.singledispatch.\n\nimport functools\nfrom collections.abc import Sequence\n\nwindow = functools.singledispatch(window)\n\n@window.register\ndef _(seq: Sequence, size=2):\n    for index in range(len(seq) - size + 1):\n        yield seq[index:index + size]\n\nlist(window('abcde'))\n\n['ab', 'bc', 'cd', 'de']\n\n\n\nlist(window(iter('abcde')))\n\n[('a', 'b'), ('b', 'c'), ('c', 'd'), ('d', 'e')]\n\n\n\nchunks = functools.singledispatch(chunks)\n\n@chunks.register\ndef _(seq: Sequence, size):\n    for index in range(0, len(seq), size):\n        yield seq[index:index + size]\n\nlist(chunks('abcde', 3))\n\n['abc', 'de']\n\n\n\nlist(chunks(iter('abcde'), 3))\n\n[('a', 'b', 'c'), ('d', 'e')]"
  },
  {
    "objectID": "posts/hardest-logic-puzzle-ever.html",
    "href": "posts/hardest-logic-puzzle-ever.html",
    "title": "Hardest Logic Puzzle Ever",
    "section": "",
    "text": "How to solve the Hardest Logic Puzzle Ever programmatically.\n\nThree gods A, B, and C are called, in no particular order, True, False, and Random. True always speaks truly, False always speaks falsely, but whether Random speaks truly or falsely is a completely random matter. Your task is to determine the identities of A, B, and C by asking three yes-no questions; each question must be put to exactly one god. The gods understand English, but will answer all questions in their own language, in which the words for yes and no are da and ja, in some order. You do not know which word means which.\n\nWith 3 binary questions, it’s possible to distinguish \\(2^3 = 8\\) scenarios. And there are \\(3! = 6\\) possibilities. Note that means it’s impossible to additionally identify what da and ja mean, as that would be \\(3! * 2 = 12\\) possibilities.\nAs always, start with modeling the data. We need a ternary enumeration for the god identifiers. It’s almost a boolean anyway, so let’s use None to indicate neither, i.e., Random. To represent the identities, a mapping from names to ids would be natural. But the mapping has to be one-to-one and onto, and using an immutable key is convenient, so an implicitly ordered tuple of names is also a valid choice. Here a named tuple represents the “state” of the world .\n\nimport itertools\nfrom typing import NamedTuple\n\nIDS = (False, True, None)\nNAMES = 'ABC'\nWORDS = ('da', 'ja')\n\nclass State(NamedTuple):\n    names: str  # order corresponds to IDS\n    yes: str\n\nSTATES = list(itertools.starmap(State, itertools.product(map(''.join, itertools.permutations(NAMES)), WORDS)))\nSTATES\n\n[State(names='ABC', yes='da'),\n State(names='ABC', yes='ja'),\n State(names='ACB', yes='da'),\n State(names='ACB', yes='ja'),\n State(names='BAC', yes='da'),\n State(names='BAC', yes='ja'),\n State(names='BCA', yes='da'),\n State(names='BCA', yes='ja'),\n State(names='CAB', yes='da'),\n State(names='CAB', yes='ja'),\n State(names='CBA', yes='da'),\n State(names='CBA', yes='ja')]\n\n\nNow to model asking a question. A typical approach would take input parameters relevant to the question, such as asking a god which one they are. And the current reality would be need to be encapsulated to answer the question.\n\ndef ask(self: State, name: str, id) -> str:\n    \"\"\"Ask `name`: are you `id`?\"\"\"\n\nThe problem with that approach is Random’s answer would have to be modeled as actually random, which would require running many simulations. Since this is a logic puzzle, it’s easier to model Random’s answer as non-deterministic, i.e., could answer either way. The question will take as input the current set of possible states, splitting the states into two groups corresponding to answers da or ja. This function will be used in a search algorithm anyway, so it’s effectively participating in the search.\n\ndef ask(name: str, id, states: set) -> dict:\n    \"\"\"Ask `name`: are you `id`? and return mapping of answers to possible states.\"\"\"\n    groups = {word: set() for word in WORDS}\n    for state in states:\n        identity = IDS[state.names.index(name)]\n        truth = identity == id\n        words = sorted(WORDS, key=state.yes.__eq__)\n        if identity in (True, None):\n            groups[words[truth]].add(state)\n        if identity in (False, None):\n            groups[words[not truth]].add(state)\n    return groups\n\nask('A', None, STATES)\n\n{'da': {State(names='ABC', yes='da'),\n  State(names='ACB', yes='da'),\n  State(names='BAC', yes='ja'),\n  State(names='BCA', yes='da'),\n  State(names='BCA', yes='ja'),\n  State(names='CAB', yes='ja'),\n  State(names='CBA', yes='da'),\n  State(names='CBA', yes='ja')},\n 'ja': {State(names='ABC', yes='ja'),\n  State(names='ACB', yes='ja'),\n  State(names='BAC', yes='da'),\n  State(names='BCA', yes='da'),\n  State(names='BCA', yes='ja'),\n  State(names='CAB', yes='da'),\n  State(names='CBA', yes='da'),\n  State(names='CBA', yes='ja')}}\n\n\nTo determine if a question is making progress, we need to look at the set of names returned for each answer. A valid solution would need to output sets of at most size \\(2^2 = 4\\) on the first question in order to proceed.\n\nfor id in IDS:\n    groups = ask('A', id, STATES)\n    identities = [{names for names, _ in group} for group in groups.values()]\n    print(id, *identities)\n\nFalse {'BAC', 'CBA', 'CAB', 'ABC', 'ACB', 'BCA'} {'CAB', 'CBA', 'BAC', 'ABC', 'ACB', 'BCA'}\nTrue {'CAB', 'CBA', 'BAC', 'ABC', 'ACB', 'BCA'} {'BAC', 'CBA', 'CAB', 'ABC', 'ACB', 'BCA'}\nNone {'BAC', 'CBA', 'CAB', 'ABC', 'ACB', 'BCA'} {'CAB', 'CBA', 'BAC', 'ABC', 'ACB', 'BCA'}\n\n\nSo that question made no progress. Unsurprising given that we don’t know which god is “Random”. Here one could resort to heuristics and increasingly convoluted questions.\nLet’s do the opposite: write the most general question possible and automate the search. Any question can be modeled by asking whether any of a given set of states is accurate.\n\ndef ask(name: str, include: set, exclude: set) -> dict:\n    \"\"\"Ask `name`: are we in any of `include` states? and return mapping of answers to possible states.\"\"\"\n    assert include.isdisjoint(exclude)\n    groups = {word: set() for word in WORDS}\n    for state in include | exclude:\n        identity = IDS[state.names.index(name)]\n        truth = state in include\n        words = sorted(WORDS, key=state.yes.__eq__)\n        if identity in (True, None):\n            groups[words[truth]].add(state)\n        if identity in (False, None):\n            groups[words[not truth]].add(state)\n    return groups\n\ninclude = set(STATES[:len(STATES) // 2])\nask('A', include, set(STATES) - include)        \n\n{'da': {State(names='ABC', yes='ja'),\n  State(names='ACB', yes='ja'),\n  State(names='BAC', yes='da'),\n  State(names='BCA', yes='da'),\n  State(names='BCA', yes='ja'),\n  State(names='CAB', yes='ja'),\n  State(names='CBA', yes='da'),\n  State(names='CBA', yes='ja')},\n 'ja': {State(names='ABC', yes='da'),\n  State(names='ACB', yes='da'),\n  State(names='BAC', yes='ja'),\n  State(names='BCA', yes='da'),\n  State(names='BCA', yes='ja'),\n  State(names='CAB', yes='da'),\n  State(names='CBA', yes='da'),\n  State(names='CBA', yes='ja')}}\n\n\nWith that, the power set of all possible combinations can be searched.\n\ndef powerset(states: set):\n    \"\"\"Generate all possible subsets.\"\"\"\n    for r in range(len(states) + 1):\n        yield from map(set, itertools.combinations(states, r))\n\ncount = 0\nfor states in powerset(STATES):\n    groups = ask('A', states, set(STATES) - states)\n    identities = [{names for names, _ in group} for group in groups.values()]\n    count += max(map(len, identities)) <= 4\ncount\n\n96\n\n\nSo there are many potential solutions. Onto automating the search.\n\ndef search(states: set, count: int = 3):\n    \"\"\"Recursively ask all possible questions until a solution is found.\"\"\"\n    identities = {names for names, _ in states}\n    if len(identities) == 1:  # solved\n        return identities.pop()\n    if not count or len(identities) > (2 ** count):  # impossible\n        return None\n    for name, subset in itertools.product(NAMES, powerset(states)):\n        groups = ask(name, subset, states - subset)\n        solutions = [search(group, count - 1) for group in groups.values()]\n        if all(solutions):\n            return name, subset, solutions\n\nsearch(set(STATES[:2]), 0)\n\n'ABC'\n\n\n\nsearch(set(STATES[:4]), 1)\n\n('A',\n {State(names='ABC', yes='da'), State(names='ACB', yes='ja')},\n ['ACB', 'ABC'])\n\n\n\nsearch(set(STATES[:6]), 2)\n\n('A',\n {State(names='ABC', yes='da'), State(names='ACB', yes='ja')},\n [('A', {State(names='ACB', yes='da')}, ['BAC', 'ACB']),\n  ('A', {State(names='ABC', yes='ja')}, ['ABC', 'BAC'])])\n\n\nSo far, so good. The output is binary tree specifying the addressed god and the states asked about at each node.\nThe sub-problems are solving a sufficient number of cases. It’s no surpise that there should be solutions asking “A” first since it can’t matter who gets the first question. Now for the real solution.\n\n%time search(set(STATES))\n\nCPU times: user 1.29 s, sys: 10.8 ms, total: 1.3 s\nWall time: 1.3 s\n\n\n('A',\n {State(names='ABC', yes='da'),\n  State(names='ACB', yes='ja'),\n  State(names='BAC', yes='ja'),\n  State(names='CAB', yes='da')},\n [('C',\n   {State(names='ACB', yes='ja'),\n    State(names='BCA', yes='da'),\n    State(names='CAB', yes='da'),\n    State(names='CBA', yes='ja')},\n   [('B',\n     {State(names='BCA', yes='ja'), State(names='CBA', yes='ja')},\n     ['BCA', 'CBA']),\n    ('A',\n     {State(names='ACB', yes='da'), State(names='CAB', yes='da')},\n     ['CAB', 'ACB'])]),\n  ('B',\n   {State(names='ABC', yes='da'),\n    State(names='BAC', yes='da'),\n    State(names='BCA', yes='ja'),\n    State(names='CBA', yes='ja')},\n   [('B',\n     {State(names='ABC', yes='da'), State(names='BCA', yes='da')},\n     ['ABC', 'BCA']),\n    ('B',\n     {State(names='BAC', yes='ja'), State(names='CBA', yes='ja')},\n     ['BAC', 'CBA'])])])\n\n\nThe puzzle is solved. Can it be simplified? Depends on your point of view.\nCanonical solutions introduce biconditionals or conterfactuals in an attempt to collapse the output possibilities. This is ultimately hopeless though, as the solution is a binary search tree regardless. Is asking a question of the form “If I asked you …, would just say ja” actually clearer than asking “Are we in any of these possibilities: …”?\nNonetheless patterns do emerge: * The first question revolves around ruling out “Random”. * Subsequent questions address non-“Random” gods.\nThe random behavior adds true complexity to the algorithm, whereas the the boolean encoding adds arbitrary complications."
  },
  {
    "objectID": "posts/accumulator.html",
    "href": "posts/accumulator.html",
    "title": "Accumulator",
    "section": "",
    "text": "A Paul Graham classic, the accumulator function.\n\nAs an illustration of what I mean about the relative power of programming languages, consider the following problem. We want to write a function that generates accumulators– a function that takes a number n, and returns a function that takes another number i and returns n incremented by i.\n\n\n(That’s incremented by, not plus. An accumulator has to accumulate.)\n\n\nIn Common Lisp this would be\n\n\n(defun foo (n) (lambda (i) (incf n i)))\n\n\n…\n\n\nIf you try to translate the Lisp/Perl/Smalltalk/Javascript code into Python you run into some limitations. Because Python doesn’t fully support lexical variables, you have to create a data structure to hold the value of n. And although Python does have a function data type, there is no literal representation for one (unless the body is only a single expression) so you need to create a named function to return. This is what you end up with:\n\n\ndef foo(n): s = [n] def bar(i): s[0] += i return s[0]  return bar\n\n\nPython users might legitimately ask why they can’t just write\n\n\ndef foo(n): return lambda i: return n += i\n\n\nor even\n\n\ndef foo(n): lambda i: n += i\n\n\nand my guess is that they probably will, one day. (But if they don’t want to wait for Python to evolve the rest of the way into Lisp, they could always just…)\n\nThere are other solutions, using function attributes or instances with a __call__ method, but none are substantially more elegant. The challenge predates Python 3, which introduced the nonlocal keyword, making this the presumably preferred solution:\n\ndef foo(n):\n    def inc(x):\n        nonlocal n\n        n += x\n        return n\n    return inc\n\nacc = foo(0)\nacc(1)\nacc(2)\n\n3\n\n\nThere was also yet another alternative as of Python 2.6: using a generator as a coroutine.\n\ndef foo(n):\n    while True:\n        n += yield n\n\nacc = foo(0)\nnext(acc)\nacc.send(1)\nacc.send(2)\n\n3\n\n\nTo satisfy the challenge, that would need to be wrapped with a decorator. The triple partial expression below may seem a little obtuse, but it’s not as bad as it looks. Just unwind it one step at a time.\n\nfrom functools import partial\n\n@partial(partial, partial)\ndef coroutine(func, *args, **kwargs):\n    gen = func(*args, **kwargs)\n    next(gen)\n    return gen.send\n\ncoroutine\n\nfunctools.partial(<class 'functools.partial'>, <function coroutine at 0x10bf970e0>)\n\n\n\n@coroutine\ndef foo(n):\n    while True:\n        n += yield n\n\nfoo\n\nfunctools.partial(<function coroutine at 0x10bf970e0>, <function foo at 0x10bf7eb90>)\n\n\n\nacc = foo(0)\nacc\n\n<function generator.send>\n\n\n\nacc(1)\nacc(2)\n\n3\n\n\nBut what’s the most Pythonic solution? This author would argue… don’t. In my experience, I have never really needed global or nonlocal in production code. Typically it’s because the objects in question are mutable, so it’s not necessary to rebind a name in a different scope to a new object.\nA typical tell of these kinds of code challenges are that they focus on the interface or implementation exclusively, never both in context. Python numbers are immutable, and have syntactic support for incrementing, so there’s nothing more readable about acc(...) instead of n += ....\nFuthermore, the accumulator object is intended to be used repeatedly, such as in a loop. In a language with such strong iteration support as Python, it’s extremely likely that accumulation will occur in a iterative loop. Indeed, the real accumulator has since been added to the standard library.\n\nimport itertools\n\nlist(itertools.accumulate(range(10)))\n\n[0, 1, 3, 6, 10, 15, 21, 28, 36, 45]"
  },
  {
    "objectID": "posts/fizz-buzz.html",
    "href": "posts/fizz-buzz.html",
    "title": "Fizz Buzz",
    "section": "",
    "text": "The infamously simple FizzBuzz problem.\nReportedly a high percentage of programmer applicants can’t solve this quickly.\n\nWrite a program that prints the numbers from 1 to 100. But for multiples of three print “Fizz” instead of the number and for the multiples of five print “Buzz”. For numbers which are multiples of both three and five print “FizzBuzz”.\n\nA deep dive on this problem has been done in jest many times, e.g., deliberate over-engineering or code golf. But in all seriousness, let’s consider what’s the most Pythonic solution. A truncated version of the common solution:\n\nfor num in range(1, 16):\n    if num % 5 == 0 and num % 3 == 0:\n        print('FizzBuzz')\n    elif num % 3 == 0:\n        print('Fizz')\n    elif num % 5 == 0:\n        print('Buzz')\n    else:\n        print(num)\n\n1\n2\nFizz\n4\nBuzz\nFizz\n7\n8\nFizz\nBuzz\n11\nFizz\n13\n14\nFizzBuzz\n\n\nNaturally interview questions tend to focus on output, e.g. print, but that’s no reason to skip over basic abstractions or data structures. First, this could be written as a generator, to decouple the print operation and parametrize the numeric range. Alternatively, Python has such strong iterator support that it could also be just a function, ready to be mapped. So let’s reframe the basic solution as:\n\ndef fizzbuzz(stop):\n    for num in range(1, stop):\n        if num % 5 == 0 and num % 3 == 0:\n            yield 'FizzBuzz'\n        elif num % 3 == 0:\n            yield 'Fizz'\n        elif num % 5 == 0:\n            yield 'Buzz'\n        else: \n            yield str(num)\n\n' '.join(fizzbuzz(16))\n\n'1 2 Fizz 4 Buzz Fizz 7 8 Fizz Buzz 11 Fizz 13 14 FizzBuzz'\n\n\nEven at this size, it’s already violating DRY, or the Rule of 3. Clearly the same logic is being repeated with different data.\n\ndef fizzbuzz(stop):\n    items = (15, 'FizzBuzz'), (3, 'Fizz'), (5, 'Buzz')\n    for num in range(1, stop):\n        yield next((text for div, text in items if num % div == 0), str(num))\n\n' '.join(fizzbuzz(16))\n\n'1 2 Fizz 4 Buzz Fizz 7 8 Fizz Buzz 11 Fizz 13 14 FizzBuzz'\n\n\nHowever, that variation had to introduce the concept of the least common multiple. Even in such a trivial problem, there’s a subtlety in how one interprets requirements. The final directive to output “FizzBuzz” can be seen as a mere clarification of the previous directives; certainly not a coincidence. Making this the more obvious solution:\n\ndef fizzbuzz(stop):\n    for num in range(1, stop):\n        text = ''\n        if num % 3 == 0:\n            text += 'Fizz'\n        if num % 5 == 0:\n            text += 'Buzz'\n        yield text or str(num)\n\n' '.join(fizzbuzz(16))\n\n'1 2 Fizz 4 Buzz Fizz 7 8 Fizz Buzz 11 Fizz 13 14 FizzBuzz'\n\n\nArguably that insight is more important, because its duplication grows exponentially, not linearly. There’s a 2**N sized case statement to handle N cases, luckily N == 2. Adding just one more directive for the number 7 would make the basic solution unwieldy.\nAnd of course both approaches can be combined.\n\ndef fizzbuzz(stop):\n    items = (3, 'Fizz'), (5, 'Buzz')\n    for num in range(1, stop):\n        yield ''.join(text for div, text in items if num % div == 0) or str(num)\n\n' '.join(fizzbuzz(16))\n\n'1 2 Fizz 4 Buzz Fizz 7 8 Fizz Buzz 11 Fizz 13 14 FizzBuzz'\n\n\nSo is that over-engineered? This author would argue that both deduplication and decoupling logic from data are worth observing. So maybe at this size the final version isn’t necessary, but surely the basic version is not the most Pythonic."
  },
  {
    "objectID": "posts/hat-puzzle.html",
    "href": "posts/hat-puzzle.html",
    "title": "Hat puzzle",
    "section": "",
    "text": "How to solve the Hat puzzle programmatically.\n\nTen-Hat Variant\n\n\nIn this variant there are 10 prisoners and 10 hats. Each prisoner is assigned a random hat, either red or blue, but the number of each color hat is not known to the prisoners. The prisoners will be lined up single file where each can see the hats in front of him but not behind. Starting with the prisoner in the back of the line and moving forward, they must each, in turn, say only one word which must be “red” or “blue”. If the word matches their hat color they are released, if not, they are killed on the spot. A friendly guard warns them of this test one hour beforehand and tells them that they can formulate a plan where by following the stated rules, 9 of the 10 prisoners will definitely survive, and 1 has a 50/50 chance of survival. What is the plan to achieve the goal?\n\nThis puzzle involves three concepts common to classic logic puzzles: * Theory of mind * Functional fixedness * Induction\nTheory of mind comes into play because each prisoner has differing knowledge, but assumes everyone else will think similarly. Functional fixedness occurs more subtly; each prisoner may state a color only to convey information. But because the information is encoded as a color, it tends to focus thinking on the colors themselves. So to combat that cognitive bias, first create a different enumeration to represent statements. Any binary enum can be mapped back to colors, so why not bool.\n\ncolors = 'red', 'blue'\ncolors[False], colors[True]\n\n('red', 'blue')\n\n\nWhich leaves induction: solve the puzzle for the base case (smallest size) first, and then methodically build on that solution. In the case of 1 prisoner, they have no information a priori, and therefore have a 50/50 chance of survival regardless of strategy. This variant of the puzzle already gives the optimal goal, so we know that everyone but the 1st can say their color and be saved, while the 1st can devote their answer to the common cause.\nIn the case of 2 prisoners, obviously the 1st can say the color of the 2nd. That approach does not scale; it is the path to functional fixedness. Instead, methodically enumerate all possible statements and colors to determine if there is an unambiguous solution.\n\ntable = list(zip([False, True], colors))\ntable\n\n[(False, 'red'), (True, 'blue')]\n\n\nThe above table is a general solution with no assumptions other than the arbitrary ordering of enums. While it may appear absurdly pedantic, it represents a rule set which is key to building a recursive solution.\nIn the case of the 3rd prisoner, clearly they can not just repeat the above rule set, because the 3rd would receive no information. But there are only 2 choices, so the only option is to follow the opposite rule set, depending on the 3rd color.\nThe crucial step is to build off of the existing table.\n\ntable = [row + colors[:1] for row in table] + [(not row[0],) + row[1:] + colors[1:] for row in table]\ntable\n\n[(False, 'red', 'red'),\n (True, 'blue', 'red'),\n (True, 'red', 'blue'),\n (False, 'blue', 'blue')]\n\n\nThe solution is valid if each prisoner is able to narrow the possibilities to a unique row based on the colors they hear and see.\n\nimport collections\n\ndef test(table):\n    \"\"\"Assert that the input table is a valid solution.\"\"\"\n    (size,) = set(map(len, table))\n    for index in range(size):\n        counts = collections.Counter(row[:index] + row[index + 1:] for row in table)\n        assert set(counts.values()) == {1}\n\ntest(table)\n\nThe general solution is simply the above logic in recursive form, with a parametrized size.\n\ndef solve(count: int):\n    \"\"\"Generate a flat table of all spoken possibilities.\"\"\"\n    if count <= 1:\n        yield False,\n        return\n    for row in solve(count - 1):\n        yield row + colors[:1]\n        yield (not row[0],) + row[1:] + colors[1:]\n\nlist(solve(3))\n\n[(False, 'red', 'red'),\n (True, 'red', 'blue'),\n (True, 'blue', 'red'),\n (False, 'blue', 'blue')]\n\n\nThe complicated puzzle is actually a trivial recurrence relation: \\[\n2^n = 2^{n-1} * 2\n\\] There are \\(2^n\\) states of the prisoners, and each prisoner has \\(n-1\\) bits of data. So an additional bit of data from the first is sufficient to solve the puzzle.\n\ntable = list(solve(10))\ntest(table)\nlen(table)\n\n512\n\n\n\ntable[:3]\n\n[(False, 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red'),\n (True, 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'blue'),\n (True, 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'blue', 'red')]\n\n\nThe puzzle is solved, but the output is of exponential size, certainly not the succinct solution which makes the puzzle famous. But instead of relying on a flash of insight, this approach produces not just a solution, but the solution. The only arbitrary decision made was the enumeration. Therefore it must be the case that the solution can be summarized.\nFirst, it would be helpful to group the solution by the 1st statement. Any summary function would have to ensure that there is no collision in the grouped possibilities.\n\ngroups = collections.defaultdict(set)\nfor row in table:\n    groups[row[0]].add(row[1:])\ngroups = groups[False], groups[True]\n\ndef summarize(func, groups):\n    \"\"\"Apply summary function to groups and assert uniqueness.\"\"\"\n    groups = tuple(set(map(func, group)) for group in groups)\n    assert set.isdisjoint(*groups)\n    return groups\n\nassert summarize(lambda g: g, groups) == groups\ntuple(map(len, groups))\n\n(256, 256)\n\n\nNow what summaries to attempt? Well there are few properties of sequences to work with: size and order. They are all the same size, so that won’t help. That leaves ordering, which can be easily tested by sorting.\n\nsummarize(lambda g: tuple(sorted(g)), groups)\n\n({('blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'red'),\n  ('blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'red', 'red', 'red'),\n  ('blue', 'blue', 'blue', 'blue', 'red', 'red', 'red', 'red', 'red'),\n  ('blue', 'blue', 'red', 'red', 'red', 'red', 'red', 'red', 'red'),\n  ('red', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red')},\n {('blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue'),\n  ('blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'blue', 'red', 'red'),\n  ('blue', 'blue', 'blue', 'blue', 'blue', 'red', 'red', 'red', 'red'),\n  ('blue', 'blue', 'blue', 'red', 'red', 'red', 'red', 'red', 'red'),\n  ('blue', 'red', 'red', 'red', 'red', 'red', 'red', 'red', 'red')})\n\n\nSuccess. Now that order does not matter, the appropriate data structure is a multiset (a.k.a. bag). Each prisoner can keep track of only how many of each color they hear and see.\n\nsummarize(lambda g: frozenset(collections.Counter(g).items()), groups)\n\n({frozenset({('blue', 8), ('red', 1)}),\n  frozenset({('blue', 2), ('red', 7)}),\n  frozenset({('blue', 6), ('red', 3)}),\n  frozenset({('blue', 4), ('red', 5)}),\n  frozenset({('red', 9)})},\n {frozenset({('blue', 1), ('red', 8)}),\n  frozenset({('blue', 7), ('red', 2)}),\n  frozenset({('blue', 5), ('red', 4)}),\n  frozenset({('blue', 3), ('red', 6)}),\n  frozenset({('blue', 9)})})\n\n\nSince there are only 2 colors which sum to a constant, keeping track of just one is sufficient.\n\nsummarize(lambda g: g.count(colors[0]), groups)\n\n({1, 3, 5, 7, 9}, {0, 2, 4, 6, 8})\n\n\nThere’s one last pattern to the numbers, which can be used to achieve parity with the canonical solution."
  },
  {
    "objectID": "posts/primes.html",
    "href": "posts/primes.html",
    "title": "Primes",
    "section": "",
    "text": "An old interview challenge is to generate prime numbers or check if a number is prime. No advanced mathematics needed, just variants on the Sieve of Eratosthenes. Starting with a basic prime checker.\n\ndef isprime(n):\n    divs = range(2, int(n ** 0.5) + 1)\n    return all(n % d for d in divs)\n\n%time isprime(1_000_003)\n\nCPU times: user 83 µs, sys: 1e+03 ns, total: 84 µs\nWall time: 85.1 µs\n\n\nTrue\n\n\nA common optimization is to skip even numbers.\n\ndef isprime(n):\n    divs = range(3, int(n ** 0.5) + 1, 2)\n    return n == 2 or all(n % d for d in divs)\n\n%time isprime(1_000_003)\n\nCPU times: user 43 µs, sys: 0 ns, total: 43 µs\nWall time: 46.3 µs\n\n\nTrue\n\n\nBrief digression on that optimization. There’s nothing special about removing multiples of 2; removing multiples is the whole point. The step scalar could instead be thought of as a cycle: itertools.accumulate(itertools.repeat(2)). So removing multiples of 3 would remove every third step: itertools.accumulate(itertools.cycle([2, 4])).\nOr the equivalent could be done with slicing.\n\nimport itertools\n\ndef isprime(n):\n    divs = range(5, int(n ** 0.5) + 1, 2)\n    return n in (2, 3) or all(n % d for d in itertools.chain(divs[::3], divs[1::3]))\n\n%time isprime(1_000_003)\n\nCPU times: user 42 µs, sys: 1 µs, total: 43 µs\nWall time: 44.1 µs\n\n\nTrue\n\n\nThe catch is the cycles grow exponentially with diminishing returns on each successive number.\nOnto prime generation, while keeping the odds-only optimization. Typically it’s requested to generate the first N primes, or up to some value. But that’s easily generalized with itertools.islice and itertools.takewhile. A more Pythonic approach is an unbounded generator.\n\ndef primes():\n    yield 2\n    ints = itertools.count(3, 2)\n    while True:\n        prime = next(ints)\n        yield prime\n        ints = (n for n in ints if n % prime)\n\nlist(itertools.islice(primes(), 10))\n\n[2, 3, 5, 7, 9, 11, 13, 15, 17, 19]\n\n\nElegant, but doesn’t work. The problem is the scoping of prime, which is being used in the generator expression but also modified in the loop. Instead it can be replaced with a filter on a partially bound function, but unfortunately functools.partial only binds left arguments and rmod is needed here. One alternative is to use bound methods as a first-class function, even dunder methods.\n\ndef primes():\n    yield 2\n    ints = itertools.count(3, 2)\n    while True:\n        prime = next(ints)\n        yield prime\n        ints = filter(prime.__rmod__, ints)\n\n%time next(itertools.islice(primes(), 1000, None))\n\nCPU times: user 30.7 ms, sys: 1.82 ms, total: 32.5 ms\nWall time: 32 ms\n\n\n7927\n\n\nElegant, but slow and could overflow the stack. A more traditional approach would use the same checking logic as isprime, but also cache the primes so as to not duplicate divisors.\n\ndef primes():\n    yield 2\n    primes = []\n    for n in itertools.count(3, 2):\n        if all(n % p for p in itertools.takewhile(int(n ** 0.5).__ge__, primes)):\n            primes.append(n)\n            yield n\n\n%time next(itertools.islice(primes(), 1000, None))\n\nCPU times: user 5.49 ms, sys: 423 µs, total: 5.92 ms\nWall time: 5.8 ms\n\n\n7927\n\n\nOnto interface design. The primes are being stored anyway, so it would be nice if they were re-iterable. A generator can be written as a class with __iter__ and __next__, but an under-appreciated feature is that __iter__ itself can be a generator. And now that it’s a class, isprime can be expressed as in while also benefiting from the cache.\n\nclass Primes:\n    def __init__(self):\n        self.ints = itertools.count(3, 2)\n        self.cache = [2]\n    \n    def __iter__(self):\n        yield from self.cache\n        for n in self.ints:\n            if n in self:\n                self.cache.append(n)\n                yield n\n\n    def __contains__(self, n):\n        return all(n % p for p in itertools.takewhile(int(n ** 0.5).__ge__, self))\n\nprimes = Primes()\n%time next(itertools.islice(primes, 1000, None))\n\nCPU times: user 7.89 ms, sys: 483 µs, total: 8.37 ms\nWall time: 8 ms\n\n\n7927\n\n\n\n%time 1_000_003 in primes\n\nCPU times: user 34 µs, sys: 0 ns, total: 34 µs\nWall time: 37 µs\n\n\nTrue\n\n\nThere’s a hybrid approach though, that’s faster and nearly as simple as the above sieves. Instead of doing repeated divisions, keep track of each found prime along with the next multiple that it would eliminate. The inner loop is then optimized because it only needs to account for collisions.\n\ndef primes():\n    multiples = {}\n    for n in itertools.count(2):\n        prime = multiples.pop(n, 0)\n        if not prime:\n            prime = n\n            yield n\n        key = n + prime\n        while key in multiples:\n            key += prime\n        multiples[key] = prime\n\n%time next(itertools.islice(primes(), 1000, None))\n\nCPU times: user 2.59 ms, sys: 103 µs, total: 2.69 ms\nWall time: 2.7 ms\n\n\n7927\n\n\nNow to add back the odds-only optimization, the step scalar needs to be double the prime number. Another way to reduce collisions is to recognize that each new prime is irrelevant until its square value is reached.\n\ndef primes():\n    yield 2\n    multiples = {}\n    for n in itertools.count(3, 2):\n        step = multiples.pop(n, 0)\n        if step:  # composite\n            key = n + step\n            while key in multiples:\n                key += step\n            multiples[key] = step\n        else:  # prime\n            multiples[n ** 2] = n * 2\n            yield n\n\n%time next(itertools.islice(primes(), 1000, None))\n\nCPU times: user 1.37 ms, sys: 5 µs, total: 1.38 ms\nWall time: 1.38 ms\n\n\n7927\n\n\nAnd finally let’s add back the caching. Yielding a clean interface, an efficient implementation for all use cases, and still relatively simple.\n\nclass Primes:\n    def __init__(self):\n        self.ints = itertools.count(3, 2)\n        self.cache = [2]\n        self.multiples = {}\n    \n    def __iter__(self):\n        yield from self.cache\n        for n in self.ints:\n            step = self.multiples.pop(n, 0)\n            if step:  # composite\n                key = n + step\n                while key in self.multiples:\n                    key += step\n                self.multiples[key] = step\n            else:  # prime\n                self.multiples[n ** 2] = n * 2\n                self.cache.append(n)\n                yield n\n\n    def __contains__(self, n):\n        return all(n % p for p in itertools.takewhile(int(n ** 0.5).__ge__, self))\n\nprimes = Primes()\n%time 1_000_003 in primes\n\nCPU times: user 242 µs, sys: 0 ns, total: 242 µs\nWall time: 245 µs\n\n\nTrue\n\n\n\n%time 1_000_003 in primes\n\nCPU times: user 40 µs, sys: 0 ns, total: 40 µs\nWall time: 43.2 µs\n\n\nTrue"
  },
  {
    "objectID": "posts/water-pouring.html",
    "href": "posts/water-pouring.html",
    "title": "Water pouring",
    "section": "",
    "text": "How to solve the water pouring puzzle programmatically.\nGiven two jugs of capcity of 3 and 5 liters, acquire exactly 4 liters in a jug. Assume an unlimited water supply, and that jugs can only be filled or emptied, i.e., no estimations.\nFirst to model the data: a mapping of jug sizes to their current quantity. There are 3 primitive operations: * filling a jug to capacity * emptying a jug entirely * pouring from a source jug to a destination jug, until either the source is emptied or the destination is full\n\nclass Jugs(dict):\n    def fill(self, size):\n        self[size] = size\n\n    def empty(self, size):\n        self[size] = 0\n    \n    def pour(self, src, dest):\n        total = self[src] + self[dest]\n        self[src] = max(total - dest, 0)\n        self[dest] = min(total, dest)\n\nThat’s sufficient to solve the puzzle through sheer brute force: scanning every possible combination breadth-first. Note the below implementations don’t terminate unless a solution is found.\n\nimport itertools\nfrom functools import partial\n\nsizes = 3, 5\noperations = list(itertools.chain(\n    (partial(Jugs.fill, size=size) for size in sizes),\n    (partial(Jugs.empty, size=size) for size in sizes),\n    (partial(Jugs.pour, src=src, dest=dest)\n         for src, dest in itertools.permutations(sizes, 2)),\n))\n\ndef search(target):\n    for n in itertools.count(1):\n        for ops in itertools.product(operations, repeat=n):\n            jugs = Jugs.fromkeys(sizes, 0)\n            states = [op(jugs) or tuple(jugs.values()) for op in ops]\n            if any(target in state for state in states):\n                return states\n\n%time search(4)\n\nCPU times: user 138 ms, sys: 2.28 ms, total: 140 ms\nWall time: 144 ms\n\n\n[(0, 5), (3, 2), (0, 2), (2, 0), (2, 5), (3, 4)]\n\n\nNow to relentlessly simplify the code. The first observation is that an empty source is useless, as is a full destination. So the fill and empty primitives are actually unneeded, and can be integrated into the pour method.\n\ndef pour(jugs, src, dest):\n    if not jugs[src]:\n        jugs[src] = src\n    if jugs[dest] >= dest:\n        jugs[dest] = 0\n    total = jugs[src] + jugs[dest]\n    jugs[src] = max(total - dest, 0)\n    jugs[dest] = min(total, dest)\n\noperations = [partial(pour, src=src, dest=dest) \n               for src, dest in itertools.permutations(sizes, 2)]\n\n%time search(4)\n\nCPU times: user 87 µs, sys: 0 ns, total: 87 µs\nWall time: 88.7 µs\n\n\n[(3, 2), (2, 0), (3, 4)]\n\n\nThat reduced the search space considerably, but moreover has revealed another simplification: it’s pointless to “undo” a pour. Whether the source was emptied or the destination was filled, whatever reversing the previous pour direction would accomplish could have been done in the first place.\nIf there were more than 2 jugs, then there could be complex workflows. But with only 2, the first choice in pour directions determines the rest. There are only 2 potential solutions to the puzzle.\n\ndef search(target, src, dest):\n    jugs = dict.fromkeys((src, dest), 0)\n    while True:\n        pour(jugs, src, dest)\n        yield tuple(jugs.values())\n        if target in jugs.values():\n            return\n\nlist(search(4, 5, 3))\n\n[(2, 3), (0, 2), (4, 3)]\n\n\n\nlist(search(4, 3, 5))\n\n[(0, 3), (1, 5), (0, 1), (0, 4)]\n\n\nAnd both of them are valid solutions. The solution to the puzzle is quite simply: keep pouring. It doesn’t even matter which to start with.\nBut it can be further simplified. Now it’s clear that the jug data structure is only providing modular arithmetic.\n\ndef search(target, src, dest):\n    for n in itertools.count(1):\n        quot, rem = divmod(n * src - target, dest)\n        if not rem:\n            return n, -quot\n\nsearch(4, 5, 3)\n\n(2, -2)\n\n\n\nsearch(4, 3, 5)\n\n(3, -1)\n\n\n\nassert (5 * 2) - (3 * 2) == (3 * 3) - (5 * 1) == 4\n\nThe puzzle is looking for integer solutions to \\[\n\\ 3x + 5y = 4\n\\] Which is known as a linear Diophantine equation, and must have a solution because \\(4\\) is a multiple of \\(gcd(3, 5)\\)."
  },
  {
    "objectID": "posts/graphql-orm.html",
    "href": "posts/graphql-orm.html",
    "title": "GraphQL - ORM",
    "section": "",
    "text": "REST and ORMs are both infamous for: * over-fetching: fetching more data than is needed per request * under-fetching: fetching less data than is needed, requiring multiple requests * select N+1 problem: under-fetching applied to multiple associated objects\nGraphQL aims to overcome REST’s shortcomings through a flexible query language, and succeeds in doing so on the client side. But on the server side, GraphQL resolvers have effectively recreated the same over- and under- fetching problems that have long plagued ORMs. The fact that ORMs remain popular despite of their inefficiency is a testament to the benefits of having in-memory objects behave consistently. There is no such trade-off for server-side GraphQL, where the only point of the objects is to be immediately serialized.\nThe so-called N+1 problem is generally acknowledged in the GraphQL community, but this article will argue only the symptoms are being addressed with workarounds like dataloader.\n\n\nThe problems can be seen immediately in GraphQL’s own introductory resolver example.\nQuery: {\n  human(obj, args, context, info) {\n    return context.db.loadHumanByID(args.id).then(\n      userData => new Human(userData)\n    )\n  }\n}\n\nHuman: {\n  name(obj, args, context, info) {\n    return obj.name\n  }\n}\nWhat makes the name resolver trivial? It’s pre-fetched by loadHumanByID, whose only parameter is id, so it’s clearly unaware of whether name has been requested. What if the requested field was a nested object, or a json field, or just a large text blob? Then one would clearly be directed towards using a non-trivial resolver which fetches the field on demand. Of course, but then whatever work is common in the human id lookup is duplicated.\nThis is by no means specific to SQL or relational databases, but SQL is a convenient lingua franca of databases to demonstrate the inefficiency. The choices are: * SELECT * FROM human WHERE id = ? * SELECT field FROM human WHERE id = ? repeated for each “expensive” field\nEven in the simplest possible example, over-fetching has already occurred, and the only proposed workaround is under-fetching. The single query we want is: * SELECT f1, f2, ... FROM human WHERE id = ? for requested fields\nIn other words, exactly what happens with ORMs, except even ORMs typically offer an option of requesting a subset of fields. Naturally the problem gets worse with list fields.\nHuman: {\n  appearsIn(obj) {\n    return obj.appearsIn // returns [ 4, 5, 6 ]\n  }\n}\n\nHuman: {\n  starships(obj, args, context, info) {\n    return obj.starshipIDs.map(\n      id => context.db.loadStarshipByID(id).then(\n        shipData => new Starship(shipData)\n      )\n    )\n  }\n}\nNow there are two sets of associate keys (.appearsIn and .starshipIDs) that have been over-fetched. Nonetheless starships is under-fetched as well. The starships resolver is neither the most efficient nor the simplest way of resolving this field: * fetch all the data by human id in the starships resolver * fetch all the data in bulk by starshipIDs * push the resolution down to the Starship layer if forced to fetch one at a time\nThe example implementation seems to be going out of its way to showcase JavaScript promises. And the assumptions being made about the underlying data store are unusual:\n\nThe data is relational in nature.\nAssociative keys have neglible cost to pre-fetch.\nBut joins are not available.\nAnd neither are primary key in queries.\n\n\n\n\nFrom GraphQL’s best practices\n\nGraphQL is designed in a way that allows you to write clean code on the server, where every field on every type has a focused single-purpose function for resolving that value. However without additional consideration, a naive GraphQL service could be very “chatty” or repeatedly load data from your databases.\n\n\nThis is commonly solved by a batching technique, where multiple requests for data from a backend are collected over a short period of time and then dispatched in a single request to an underlying database or microservice by using a tool like Facebook’s DataLoader.\n\nThat’s an understatement. It’s not clear how “naive” differs from best practice.\nClearly there is value in transforming multiple primary key = queries into a single primary key in query. As in the starships example however, that can be done more simply in the parent resolver. There is more value in not needing a primary key in query at all. Furthermore adding caching to a dataloader avoids the central issue.\nAgain reminiscent of ORMs, any data layer can add caching. The point is efficiently resolving a query requires context, which strict adherence to single-purpose resolvers explictly disregards.\n\n\n\nThe inefficencies becomes even more glaring when moving beyond associative keys. Nearly any aggregation requires knowing what summaries are requested. Such as if the appearsIn field optionally included counts or times. Using SQL as an example again, the query would resemble one of: * SELECT distinct field FROM ... * SELECT field, count(*) FROM ... GROUP BY field\nThe conditional logic if \"count\" in requested_fields must exist in some form in the code, because the alternatives are over-fetching or under-fetching. Both of which are far more inefficient in this scenario than in the “select N+1” problem. A dataloader-esque approach is not going to be applicable to “group by” operations.\n\n\n\nOne last generalized example: computed fields. What are typically query flags in REST (and RPC) APIs, become field selections in GraphQL.\nFor example, computing scores in a search engine interface. Instead of a scores: Boolean! = false input option, the more obvious approach would be to skip score calculation when the score field isn’t requested.\nAs with aggregation, the same pattern recurs. It’s unacceptable to over-fetch, i.e., compute the scores when not needed. It’s worse still to under-fetch, i.e., run some sort of lean search that will find matches and then go back and compute scores later.\n\n\n\nThe inescapable conclusion is that in some cases parent resolvers need to know which of their children are being requested. There’s no need to throw away GraphQL’s server-side resolver hierarchy. No one is advocating a thousand line root resolver named RunIt that processes the entire query.\nAll that’s needed is a conceptual shift which encourages introspecting the GraphQLResolveInfo object. The requested fields are right there waiting to be useful, but good luck finding documentation and examples to that effect. In every non-trivial GraphQL project, this author has used a utility like:\n\ndef selections(node):\n    \"\"\"Return tree of field name selections.\"\"\"\n    nodes = getattr(node.selection_set, 'selections', [])\n    return {node.name.value: selections(node) for node in nodes}\n\nThose fields would be checked or passed to a data layer as needed. For example, in Django’s ORM, it could be as simple as appending a query set with .values(*selections(*info.nodes)).\nWell, almost. The next issue is that typical GraphQL model validators raise an error if required fields are missing. Thanks validator; the field is missing because the client didn’t request it.\nThis is actually a different age-old problem: equivocating “optional” and “nullable”. GraphQL requires populating all requested fields, and specifiying whether they may be null. Server-side implementations understandably, but still incorrectly, interpret that by making nullables optional and non-nullables required at the model layer. So typically it’s necessary to pad resolved objects with empty (but not null) data.\nAlthough a minor problem, it reveals the bias related to single-purpose resolvers. The point of GraphQL is to efficiently return only the requested fields, yet standard practice in GraphQL models is to require populating fields that haven’t been requested.\nOver- and under- fetching can be addressed directly in resolvers, with the data layer’s own interface, instead of hidden behind another abstraction layer."
  },
  {
    "objectID": "posts/coin-balance.html",
    "href": "posts/coin-balance.html",
    "title": "Coin balance",
    "section": "",
    "text": "How to solve the coin balance puzzle programmatically.\nGiven a balance and a set of coins, which are all equal in weight except for one, determine which coin is of different weight in as few weighings as possible.\n\nTwelve-coin problem\n\n\nA more complex version has twelve coins, eleven or twelve of which are identical. If one is different, we don’t know whether it is heavier or lighter than the others. This time the balance may be used three times to determine if there is a unique coin—and if there is, to isolate it and determine its weight relative to the others. (This puzzle and its solution first appeared in an article in 1945.[2]) The problem has a simpler variant with three coins in two weighings, and a more complex variant with 39 coins in four weighings.\n\nFirst to model the data: * An enum to represent different weights. Following the ternary comparison convention, such as Python 2’s cmp, is convenient. * An object to represent the balance. For testing, it will need to be configurable with the target coin and relative weight. * An object to represent a coin and its state. A class is tempting, but the most useful data structure would keep the coins grouped by their known (or unknown) state anyway. So any hashable unique identifier is sufficient.\n\nimport enum\n\nclass Weight(enum.IntEnum):\n    LIGHT = -1\n    EVEN = 0\n    HEAVY = 1\n\nclass Balance:\n    def __init__(self, coin, weight: Weight):\n        self.coin = coin\n        self.weight = weight\n\n    def weigh(self, left: set, right: set):\n        \"\"\"Return relative Weight of left side to right side.\"\"\"\n        assert len(left) == len(right)\n        if self.coin in left:\n            return self.weight\n        if self.coin in right:\n            return Weight(-self.weight)\n        return Weight.EVEN\n\ncoins = 'abcdefghijkl'\nassert len(coins) == 12\nbalance = Balance('a', Weight.LIGHT)\nassert balance.weigh('a', 'b') == Weight.LIGHT\nassert balance.weigh('b', 'c') == Weight.EVEN\nassert balance.weigh('b', 'a') == Weight.HEAVY\n\nAs is typical with induction puzzles, the constants chosen are just large enough to thwart an iterative approach. The 2 weighing variation would be trivial enough for most people to brute force the solution. Whereas 4 weighings would already be such a large decision tree, it would be tedious to even output. The easier approach is solve the puzzle recursively and more generally, for any number of coins and weighings.\nSo what can be done in a single weighing? Clearly all weighings must have an equal number of coins on each side, else nothing is learned. If it balances, then the different coin is in the unweighed group. If it doesn’t balance, then the different coin is in the weighed group, but additionally it is known whether each coin would be heavy or light based on which side it was on. This is the crucial insight: there’s a variant recursive puzzle embedded inside this puzzle.\nThe Towers of Hanoi is a classic puzzle often used in computer science curricula to teach recursion. This one would suitable as a subsequent more advanced problem.\nSo what can be done with known coins in a single weighing? If it balances, then as before the different coin is in the unweighed group. But if it doesn’t balance, then which way can be used to further narrow the coins. Consider the heavier side; the different coin must be one of the heavy ones on that side, or one of the light ones on the other side. Therefore the coins can be split into 2 equal sized groups by putting equal numbers of heavy coins on each side, and equal numbers of light coins on each side. One obstacle is that if there aren’t an even number, there will need to be filler coins just to balance. But that won’t be a problem after the first weighing.\nNow we can implement a solution to the sub-problem, and build the need for filler coins into the balance implementation. A generator is used so that the output of each weighing can be displayed.\n\nimport itertools\n\nclass Balance:\n    def __init__(self, coin, weight: Weight):\n        self.coin = coin\n        self.weight = weight\n        self.filler = set()\n\n    def weigh(self, left: set, right: set):\n        \"\"\"Return relative Weight of left side to right side.\"\"\"\n        assert abs(len(left) - len(right)) <= len(self.filler)\n        if self.coin in left:\n            return self.weight\n        if self.coin in right:\n            return Weight(-self.weight)\n        return Weight.EVEN\n\n    def find(self, light: set, heavy: set):\n        \"\"\"Recursively find target coin from sets of potentially light and heavy coins.\"\"\"\n        yield light, heavy\n        union = light | heavy\n        if len(union) <= 1:\n            return\n        left, right = set(), set()\n        # split into 3 groups\n        for start, third in enumerate([left, right]):\n            for group in (light, heavy):\n                third.update(itertools.islice(group, start, None, 3))\n        weight = self.weigh(left, right)\n        if weight < 0:\n            light, heavy = (light & left), (heavy & right)\n        elif weight > 0:\n            light, heavy = (light & right), (heavy & left)\n        else:\n            light, heavy = (light - left - right), (heavy - left - right)\n        self.filler.update(union - light - heavy)\n        yield from self.find(light, heavy)\n\nbalance = Balance('a', Weight.LIGHT)\nfor light, heavy in balance.find(set('abc'), set('def')):\n    print(''.join(light), ''.join(heavy))\n\ncba dfe\na e\na \n\n\nNow with the sub-problem solved, there’s just one thing missing for the main puzzle. In the known case, splitting into 3 equal sized groups is cleary optimal. But in the unknown case, we need to know how many coins to exclude from the weighing. This requires computing how many coins can be handled in the subsolution. Luckily it’s a trivial recurrence relation: n weighings can solve 3 times the number of n - 1 weighings. \\[\n\\prod_{}^n 3 = 3^n\n\\]\n\nclass Balance(Balance):\n    def solve(self, count: int, coins):\n        \"\"\"Recursively find target coin.\"\"\"\n        if count <= 0:\n            return\n        weigh = set(itertools.islice(coins, 3 ** (count - 1) - (not self.filler)))\n        exclude = set(coins) - weigh\n        left, right = (set(itertools.islice(weigh, start, None, 2)) for start in range(2))\n        weight = self.weigh(left, right)\n        self.filler.update(exclude if weight else weigh)\n        if weight < 0:\n            yield from self.find(left, right)\n        elif weight > 0:\n            yield from self.find(right, left)\n        else:\n            yield from self.solve(count - 1, exclude)\n\nbalance = Balance('a', Weight.LIGHT)\nfor light, heavy in balance.solve(3, coins):\n    print(''.join(light), ''.join(heavy))\n\nfor coin in coins:\n    light, heavy =  list(Balance(coin, Weight.LIGHT).solve(3, coins))[-1]\n    assert light == {coin} and not heavy\n    light, heavy =  list(Balance(coin, Weight.HEAVY).solve(3, coins))[-1]\n    assert not light and heavy == {coin}\n\ndbah fceg\na e\na \n\n\nThe puzzle is solved. There’s one last simplifcation that can be made, but requires a bit more math background. Ideally we wouldn’t need to know the objective number of weighings; the algorithm would just solve any set of coins as efficiently as possible. To do that, the number of coins that can be solved has to be computed. As was done above, but this recurrence relation is more advanced: each weighing can solve 3 ^ n more coins. \\[\n\\sum_{k=0}^{n-1} 3^k = (3^n - 1) / 2\n\\]\nWith that calculation inverted, the count can be removed from the interface\n\nimport math\n\nclass Balance(Balance):\n    def solve(self, coins):\n        if not coins:\n            return\n        count = math.ceil(math.log(len(coins) * 2 + 1, 3))\n        weigh = set(itertools.islice(coins, 3 ** (count - 1) - (not self.filler)))\n        exclude = set(coins) - weigh\n        left, right = (set(itertools.islice(weigh, start, None, 2)) for start in range(2))\n        weight = self.weigh(left, right)\n        self.filler.update(exclude if weight else weigh)\n        if weight < 0:\n            yield from self.find(left, right)\n        elif weight > 0:\n            yield from self.find(right, left)\n        else:\n            yield from self.solve(exclude)\n\nbalance = Balance('a', Weight.LIGHT)\nfor light, heavy in balance.solve(coins):\n    print(''.join(light), ''.join(heavy))\n\ndbah fceg\na e\na \n\n\nNotice the formula indicates it’s possible to do 13 coins in 3 weighings, and it would be with a filler coin to balance out the 9 that need weighing."
  },
  {
    "objectID": "posts/random-selection.html",
    "href": "posts/random-selection.html",
    "title": "Random Selection",
    "section": "",
    "text": "Random selection utilities used to be common in interviews. Less so in Python circles because of the builtin random module. Still advanced examples may come up. First is a generalization of shuffle and sample.\n\nimport itertools\nimport random\n\ndef shuffled(iterable):\n    \"\"\"Generate values in random order for any iterable.\n    \n    Faster than `random.shuffle` if not all values are required.\n    More flexible than `random.sample` if the desired number is unknown a priori.\n    \"\"\"\n    values = list(iterable)\n    while values:\n        index = random.randrange(0, len(values))\n        values[index], values[-1] = values[-1], values[index]\n        yield values.pop()\n\nlist(itertools.islice(shuffled(range(10)), 5))\n\n[9, 7, 5, 4, 6]\n\n\nNext up is a random sample in a single pass, e.g., if the data is being read from a large file. The solution requires mathematical induction: * each Nth element has a fair chance of being selected * each previously selected element has a fair chance of being removed\n\ndef sample(iterable, k):\n    \"\"\"Return a random sample from any iterable in a single pass.\n    \n    More memory efficient than `random.sample`.\n    \"\"\"\n    it = iter(iterable)\n    selection = list(itertools.islice(it, k))\n    # error handling and shuffling are consistent with random.sample\n    if not 0 <= k <= len(selection):\n        raise ValueError(\"sample larger than population\")\n    random.shuffle(selection)\n    for count, value in enumerate(it, k + 1):\n        index = random.randrange(0, count)\n        if index < len(selection):\n            selection[index] = value\n    return selection\n\nsample(iter(range(10)), 5)\n\n[1, 2, 6, 3, 8]"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Pythonicity",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\nRandom Selection\n\n\nGenerate random numbers efficiently.\n\n\n\n\ninterviews\n\n\n\n\n\n\n\n\n\n\n\nJan 2, 2023\n\n\nA. Coady\n\n\n\n\n\n\n\n\nPrimes\n\n\nGenerate prime numbers.\n\n\n\n\ninterviews\n\n\n\n\n\n\n\n\n\n\n\nJul 10, 2021\n\n\nA. Coady\n\n\n\n\n\n\n\n\nHardest Logic Puzzle Ever\n\n\nHow to solve the Hardest Logic Puzzle Ever programmatically.\n\n\n\n\npuzzles\n\n\n\n\n\n\n\n\n\n\n\nJan 1, 2021\n\n\nA. Coady\n\n\n\n\n\n\n\n\nGraphQL - ORM\n\n\nGraphQL is the new ORM.\n\n\n\n\nstyle\n\n\n\n\n\n\n\n\n\n\n\nJul 6, 2020\n\n\nA. Coady\n\n\n\n\n\n\n\n\nClosing files\n\n\nContrarian view on closing files.\n\n\n\n\nstyle\n\n\n\n\n\n\n\n\n\n\n\nJul 5, 2020\n\n\nA. Coady\n\n\n\n\n\n\n\n\nMutable defaults\n\n\nContrarian view on mutable default arguments.\n\n\n\n\nstyle\n\n\n\n\n\n\n\n\n\n\n\n\nJun 28, 2020\n\n\nA. Coady\n\n\n\n\n\n\n\n\nWater pouring\n\n\nHow to solve the water pouring puzzle programmatically.\n\n\n\n\npuzzles\n\n\n\n\n\n\n\n\n\n\n\nJun 14, 2020\n\n\nA. Coady\n\n\n\n\n\n\n\n\nCoin balance\n\n\nHow to solve the coin balance puzzle programmatically.\n\n\n\n\npuzzles\n\n\n\n\n\n\n\n\n\n\n\nJun 7, 2020\n\n\nA. Coady\n\n\n\n\n\n\n\n\nHat puzzle\n\n\nHow to solve the Hat puzzle programmatically.\n\n\n\n\npuzzles\n\n\n\n\n\n\n\n\n\n\n\nJan 11, 2020\n\n\nA. Coady\n\n\n\n\n\n\n\n\nSplit an Iterable\n\n\nSplit an iterable into equal sized chunks.\n\n\n\n\ninterviews\n\n\n\n\n\n\n\n\n\n\n\nDec 28, 2019\n\n\nA. Coady\n\n\n\n\n\n\n\n\nAccumulator\n\n\nA Paul Graham classic, the accumulator function.\n\n\n\n\nstyle\n\n\n\n\n\n\n\n\n\n\n\nMay 28, 2018\n\n\nA. Coady\n\n\n\n\n\n\n\n\nMap and Filter\n\n\nContrarian view on map and filter.\n\n\n\n\nstyle\n\n\n\n\n\n\n\n\n\n\n\nMar 31, 2018\n\n\nA. Coady\n\n\n\n\n\n\n\n\nFizz Buzz\n\n\nThe infamously simple FizzBuzz problem.\n\n\n\n\ninterviews\n\n\n\n\n\n\n\n\n\n\n\nMar 25, 2018\n\n\nA. Coady\n\n\n\n\n\n\n\n\nCheryl’s Birthday\n\n\nHow to solve the Cheryl’s Birthday puzzle programmatically.\n\n\n\n\npuzzles\n\n\n\n\n\n\n\n\n\n\n\nMar 20, 2018\n\n\nA. Coady\n\n\n\n\n\n\nNo matching items"
  }
]